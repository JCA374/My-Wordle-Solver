{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat GPT 4 Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Word Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_gist_content(gist_url):\n",
    "    # Extract the gist ID from the URL\n",
    "    gist_id = gist_url.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # Construct the URL for the raw content\n",
    "    raw_url = f\"https://gist.githubusercontent.com/dracos/{gist_id}/raw/\"\n",
    "    \n",
    "    response = requests.get(raw_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return string_to_list(response.text)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def string_to_list(input_string):\n",
    "    # Split the string by newline to get a list of words and remove any leading/trailing whitespace\n",
    "    return [word.upper() for word in input_string.strip().split(\"\\n\")]\n",
    "\n",
    "def get_old_words():\n",
    "    url = \"https://www.rockpapershotgun.com/wordle-past-answers\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    oldwords = []\n",
    "    for li in soup.select(\"ul.inline li\"):\n",
    "        oldwords.append(li.text)\n",
    "    return oldwords\n",
    "\n",
    "def get_frequency_list():\n",
    "    # Define the file name\n",
    "    file_name = \"five_letter_frequency_list.txt\"\n",
    "\n",
    "    # Initialize an empty dictionary\n",
    "    word_frequency_dict = {}\n",
    "\n",
    "    # Read the contents of the file and parse into a dictionary\n",
    "    try:\n",
    "        with open(file_name, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                word, number = line.strip().split('\\t')\n",
    "                word_frequency_dict[word] = int(number)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_name}' not found.\")\n",
    "\n",
    "    return word_frequency_dict\n",
    "\n",
    "def remove_words(five_letter_words, OldWords):\n",
    "    \"\"\"Removes all words from `five_letter_words` that are also in `OldWords`.\"\"\"\n",
    "    return [word for word in five_letter_words if word not in OldWords]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word_frequency_dict and turn it into a list of words\n",
    "word_frequency_dict = get_frequency_list()\n",
    "word_frequency_list = list(word_frequency_dict.keys())\n",
    "\n",
    "#Get old words and remove them from above list\n",
    "oldwords = get_old_words()\n",
    "current_word_list = remove_words(word_frequency_list, oldwords)\n",
    "\n",
    "#Remove Words not accsepted by wordel\n",
    "temp_words = ['AERIO', 'CMNTS']\n",
    "current_word_list = remove_words(current_word_list, temp_words)\n",
    "\n",
    "#Calulate the letter frequency\n",
    "letter_frequency = Counter(\"\".join(current_word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: AROSE, Score: 79604\n",
      "Word: CLINT, Score: 51667\n"
     ]
    }
   ],
   "source": [
    "# Now we can calculate the scores and proceed with finding the two best words:\n",
    "\n",
    "def calculate_word_score(word, letter_frequency):\n",
    "    # The score of a word is the sum of its letters' frequencies\n",
    "    return sum(letter_frequency[letter] for letter in word)\n",
    "\n",
    "# Calculate the score for each word\n",
    "word_scores = {word: calculate_word_score(word, letter_frequency) for word in current_word_list}\n",
    "\n",
    "\n",
    "\n",
    "# Sort the words by their scores in descending order\n",
    "sorted_words_by_score = sorted(word_scores, key=word_scores.get, reverse=True)\n",
    "\n",
    "# Find the top two words with the highest scores that do not share any letters\n",
    "top_two_words = []\n",
    "for word in sorted_words_by_score:\n",
    "    if all(word.count(letter) == 1 for letter in word):  # Ensure the word has all unique letters\n",
    "        if not top_two_words:  # If this is the first word, just add it\n",
    "            top_two_words.append(word)\n",
    "        else:\n",
    "            first_word_letters = set(top_two_words[0])\n",
    "            if not any(letter in first_word_letters for letter in word):  # Ensure no shared letters\n",
    "                top_two_words.append(word)\n",
    "                break  # We found our two words, so we can stop searching\n",
    "\n",
    "# Print the top two words and their scores\n",
    "for word in top_two_words:\n",
    "    print(f\"Word: {word}, Score: {word_scores[word]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
