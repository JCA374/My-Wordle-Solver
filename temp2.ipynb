{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all 5 Letter Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\jonca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 5-letter words in English: 10230\n",
      "Example 5-letter words:\n",
      "['DONGA', 'SCAUR', 'GUARD', 'SCAWL', 'ICACO', 'OBOLE', 'HULKY', 'LUCIA', 'LEITH', 'WESTY', 'TUBIG', 'KUBBA', 'UVIOL', 'RENAL', 'UMPTY', 'CRARE', 'BUSSU', 'MOTTO', 'YAHOO', 'CORYL', 'IHRAM', 'BEGAR', 'PODGY', 'DEINO', 'BOSOM', 'NIKKO', 'DARKY', 'BITCH', 'KITAR', 'SAWAH', 'TEKKE', 'BESSI', 'QUIRT', 'SWART', 'CAVUS', 'DRAKE', 'ASKER', 'SPITE', 'JABUL', 'TEEMS', 'APTAL', 'SHOOT', 'MADAM', 'SCARP', 'GALOP', 'INURN', 'GRAMP', 'TIBIA', 'LUNCH', 'ZIMME', 'SPEOS', 'TUISM', 'DONUM', 'ASCOT', 'JEWRY', 'ERUCA', 'KABEL', 'RIMER', 'NESTY', 'ALLAY', 'CURIN', 'OXANE', 'QUARL', 'ENOIL', 'AMUSE', 'WRAWL', 'PAUXI', 'ROMAN', 'SCRUM', 'FACET', 'VEDDA', 'YACHT', 'WEFTY', 'STOUN', 'NATAL', 'SHUNT', 'SABZI', 'BANAT', 'FERRY', 'BEBAT', 'TOISE', 'WHEAM', 'WICKY', 'LOGIC', 'CHURN', 'ROUGH', 'MUCKY', 'DARST', 'POPPA', 'DAMAN', 'FROTH', 'EPHOR', 'SIZAR', 'SEMIC', 'GLUER', 'AWASH', 'GRUSH', 'CLEAM', 'SKILL', 'LAMMY']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the English words dataset if you haven't already\n",
    "nltk.download('words')\n",
    "\n",
    "# Import the English words\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Function to get all 5-letter words\n",
    "# Här får vi alla 5 bokstäver lpnga ord i listan \"five_letter_words\"\n",
    "def get_5_letter_words():\n",
    "  english_words = set(words.words())\n",
    "  five_letter_words = [word.upper() for word in english_words if len(word) == 5 and word.isalpha()]\n",
    "\n",
    "\n",
    "  return five_letter_words\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    five_letter_words = get_5_letter_words()\n",
    "    print(f\"Total 5-letter words in English: {len(five_letter_words)}\")\n",
    "    print(\"Example 5-letter words:\")\n",
    "    print(five_letter_words[:100])  # Print the first 10 words as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finds all used words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABACK', 'ABASE', 'ABATE', 'ABBEY', 'ABOUT', 'ABOVE', 'ABYSS', 'ACRID', 'ACUTE', 'ADMIT', 'ADOBE', 'ADOPT', 'ADORE', 'ADULT', 'AGAIN', 'AGAPE', 'AGATE', 'AGENT', 'AGILE', 'AGLOW', 'AGONY', 'AGREE', 'AHEAD', 'ALBUM', 'ALIEN', 'ALIKE', 'ALLOW', 'ALOFT', 'ALONE', 'ALOUD', 'ALPHA', 'ALTAR', 'ALTER', 'AMBER', 'AMISS', 'AMPLE', 'ANGEL', 'ANGER', 'ANGRY', 'ANODE', 'ANTIC', 'AORTA', 'APHID', 'APPLE', 'APPLY', 'APRON', 'APTLY', 'ARBOR', 'ARGUE', 'AROMA', 'ASIDE', 'ASKEW', 'ASSET', 'ATOLL', 'ATONE', 'AUDIO', 'AUDIT', 'AVAIL', 'AVERT', 'AWAIT', 'AWAKE', 'AWFUL', 'AXIOM', 'AZURE', 'BADGE', 'BADLY', 'BAGEL', 'BAKER', 'BALSA', 'BANAL', 'BARGE', 'BASIC', 'BATHE', 'BATON', 'BATTY', 'BAYOU', 'BEACH', 'BEADY', 'BEAST', 'BEEFY', 'BEGET', 'BEGIN', 'BEING', 'BELCH', 'BELIE', 'BELLY', 'BELOW', 'BENCH', 'BERET', 'BERTH', 'BESET', 'BINGE', 'BIOME', 'BIRCH', 'BIRTH', 'BLACK', 'BLAME', 'BLAND', 'BLEED', 'BLEEP', 'BLOKE', 'BLOWN', 'BLUFF', 'BLURB', 'BLURT', 'BLUSH', 'BOOBY', 'BOOST', 'BOOZE', 'BOOZY', 'BORAX', 'BOUGH', 'BRAID', 'BRAKE', 'BRASH', 'BRAVE', 'BREAD', 'BREAK', 'BRIAR', 'BRIBE', 'BRIDE', 'BRINE', 'BRING', 'BRINK', 'BRISK', 'BROKE', 'BROOK', 'BROOM', 'BRUSH', 'BUGGY', 'BULLY', 'BUNCH', 'BURLY', 'CACAO', 'CACHE', 'CANNY', 'CANOE', 'CAPER', 'CARAT', 'CARGO', 'CARRY', 'CAROL', 'CATCH', 'CATER', 'CAULK', 'CEDAR', 'CHAFE', 'CHAMP', 'CHANT', 'CHARD', 'CHARM', 'CHART', 'CHEAT', 'CHEEK', 'CHEST', 'CHIEF', 'CHILL', 'CHIME', 'CHOIR', 'CHOKE', 'CHORD', 'CHUNK', 'CHUTE', 'CIDER', 'CIGAR', 'CINCH', 'CIRCA', 'CIVIC', 'CLASS', 'CLEAN', 'CLEAR', 'CLERK', 'CLICK', 'CLING', 'CLOCK', 'CLOSE', 'CLOTH', 'CLOWN', 'CLUCK', 'COACH', 'COAST', 'COCOA', 'COLON', 'COMET', 'COMMA', 'CONDO', 'CONIC', 'CORNY', 'COULD', 'COUNT', 'COVET', 'COWER', 'COYLY', 'CRAMP', 'CRANE', 'CRANK', 'CRASS', 'CRATE', 'CRAVE', 'CRAZE', 'CRAZY', 'CREAK', 'CREDO', 'CREPT', 'CRIME', 'CRIMP', 'CROAK', 'CRONE', 'CROSS', 'CRUMB', 'CRUST', 'CURLY', 'CYNIC', 'DADDY', 'DANCE', 'DANDY', 'DEATH', 'DEBUG', 'DELTA', 'DELVE', 'DENIM', 'DEPOT', 'DEPTH', 'DIGIT', 'DINER', 'DISCO', 'DITTO', 'DODGE', 'DONOR', 'DONUT', 'DOUBT', 'DOWRY', 'DOZEN', 'DRAIN', 'DREAM', 'DRINK', 'DRIVE', 'DROLL', 'DROOP', 'DUCHY', 'DUTCH', 'DUVET', 'DWARF', 'DWELL', 'DWELT', 'EARTH', 'EGRET', 'EJECT', 'ELDER', 'ELOPE', 'ELUDE', 'EMAIL', 'EMPTY', 'ENEMA', 'ENJOY', 'ENNUI', 'ENTER', 'EPOCH', 'EPOXY', 'EQUAL', 'ERODE', 'ERROR', 'ESSAY', 'ETHIC', 'ETHOS', 'EVADE', 'EVERY', 'EXACT', 'EXCEL', 'EXERT', 'EXIST', 'EXTRA', 'EXULT', 'FARCE', 'FAULT', 'FAVOR', 'FEAST', 'FEIGN', 'FERRY', 'FEWER', 'FIELD', 'FIEND', 'FIFTY', 'FINER', 'FIRST', 'FISHY', 'FIXER', 'FJORD', 'FLAIL', 'FLAIR', 'FLANK', 'FLASK', 'FLESH', 'FLICK', 'FLING', 'FLIRT', 'FLOAT', 'FLOCK', 'FLOOD', 'FLOOR', 'FLORA', 'FLOSS', 'FLOUT', 'FLUFF', 'FLUME', 'FLYER', 'FOCAL', 'FOCUS', 'FOGGY', 'FOLLY', 'FORAY', 'FORGE', 'FORGO', 'FORTH', 'FOUND', 'FOYER', 'FRAME', 'FRANK', 'FRESH', 'FROCK', 'FRONT', 'FROST', 'FROTH', 'FROZE', 'FUNGI', 'GAMER', 'GAMMA', 'GAUDY', 'GAUZE', 'GAWKY', 'GECKO', 'GHOUL', 'GIANT', 'GIDDY', 'GIRTH', 'GLASS', 'GLEAN', 'GLOAT', 'GLOOM', 'GLORY', 'GLOVE', 'GLYPH', 'GNASH', 'GOLEM', 'GONER', 'GOOSE', 'GORGE', 'GOUGE', 'GRADE', 'GRAND', 'GRAPH', 'GRATE', 'GREAT', 'GREET', 'GRIEF', 'GRIME', 'GRIMY', 'GRIPE', 'GROIN', 'GROUP', 'GROUT', 'GROVE', 'GROWL', 'GRUEL', 'GUANO', 'GUARD', 'GUEST', 'GUILD', 'GULLY', 'GUPPY', 'HAIRY', 'HAPPY', 'HATCH', 'HATER', 'HAVOC', 'HEADY', 'HEART', 'HEATH', 'HEIST', 'HELIX', 'HELLO', 'HERON', 'HINGE', 'HOARD', 'HOBBY', 'HOMER', 'HORDE', 'HORSE', 'HOTEL', 'HOUND', 'HOWDY', 'HUMAN', 'HUMID', 'HUMOR', 'HUMPH', 'HUNKY', 'HURRY', 'HUTCH', 'HYPER', 'IGLOO', 'IMPEL', 'INANE', 'INDEX', 'INEPT', 'INERT', 'INFER', 'INPUT', 'INTER', 'IONIC', 'IRATE', 'IRONY', 'ISLET', 'ITCHY', 'IVORY', 'JAUNT', 'JAZZY', 'JOKER', 'JOUST', 'JUDGE', 'KARMA', 'KAYAK', 'KAZOO', 'KEBAB', 'KHAKI', 'KIOSK', 'KNEEL', 'KNELT', 'KNOCK', 'KNOLL', 'KOALA', 'LABEL', 'LABOR', 'LAPEL', 'LAPSE', 'LARVA', 'LATTE', 'LAYER', 'LEAFY', 'LEAKY', 'LEAPT', 'LEAVE', 'LEDGE', 'LEERY', 'LEMON', 'LIBEL', 'LIGHT', 'LILAC', 'LINEN', 'LIVER', 'LOCUS', 'LOFTY', 'LOGIC', 'LOOPY', 'LOSER', 'LOVER', 'LOWLY', 'LOYAL', 'LUCKY', 'LUNAR', 'LUSTY', 'LYING', 'MADAM', 'MAGIC', 'MAGMA', 'MAIZE', 'MAJOR', 'MANLY', 'MANOR', 'MAPLE', 'MARCH', 'MARRY', 'MARSH', 'MASSE', 'MATEY', 'MAXIM', 'MAYBE', 'MEALY', 'MEDAL', 'MERCY', 'MERIT', 'MERRY', 'METAL', 'METRO', 'MIDGE', 'MIDST', 'MIMIC', 'MINCE', 'MODEL', 'MOIST', 'MOLAR', 'MONEY', 'MONTH', 'MOOSE', 'MOSSY', 'MOTOR', 'MOTTO', 'MOULT', 'MOUNT', 'MOURN', 'MOUSE', 'MOVIE', 'MUCKY', 'MUMMY', 'MUSIC', 'NAIVE', 'NANNY', 'NASTY', 'NATAL', 'NAVAL', 'NEEDY', 'NIGHT', 'NINTH', 'NYMPH', 'OCCUR', 'OCEAN', 'OFFAL', 'OLDER', 'OLIVE', 'ONION', 'ONSET', 'OPERA', 'OTHER', 'OUGHT', 'OUTDO', 'OXIDE', 'PANEL', 'PANIC', 'PAPER', 'PARER', 'PARRY', 'PARTY', 'PATTY', 'PAUSE', 'PEACE', 'PEACH', 'PERCH', 'PERKY', 'PHASE', 'PHOTO', 'PICKY', 'PIETY', 'PILOT', 'PINEY', 'PINKY', 'PINTO', 'PITHY', 'PIXIE', 'PLANK', 'PLANT', 'PLATE', 'PLAZA', 'PLEAT', 'PLUCK', 'PLUNK', 'POINT', 'POISE', 'POKER', 'POLKA', 'POLYP', 'POUND', 'POWER', 'PRICK', 'PRIDE', 'PRIME', 'PRIMO', 'PRINT', 'PRIZE', 'PROBE', 'PROVE', 'PROXY', 'PULPY', 'PURGE', 'QUALM', 'QUART', 'QUERY', 'QUEST', 'QUICK', 'QUIET', 'QUIRK', 'QUOTE', 'RADIO', 'RAINY', 'RAMEN', 'RANCH', 'RANGE', 'RATIO', 'RAYON', 'REACT', 'REBUS', 'REBUT', 'RECAP', 'REGAL', 'RENEW', 'REPAY', 'RETCH', 'RETRO', 'REVEL', 'RHINO', 'RHYME', 'RIGHT', 'RIPER', 'RIVAL', 'ROBIN', 'ROBOT', 'ROCKY', 'RODEO', 'ROGUE', 'ROOMY', 'ROUGE', 'ROUND', 'ROUSE', 'ROYAL', 'RUDDY', 'RUDER', 'RUPEE', 'RUSTY', 'SAINT', 'SALAD', 'SALSA', 'SAUTE', 'SCALD', 'SCARE', 'SCARF', 'SCOLD', 'SCORN', 'SCOUR', 'SCOUT', 'SCRAP', 'SCRUB', 'SEDAN', 'SEEDY', 'SERVE', 'SEVER', 'SHAKE', 'SHALL', 'SHAME', 'SHARD', 'SHAWL', 'SHINE', 'SHIRE', 'SHIRK', 'SHORN', 'SHOWN', 'SHOWY', 'SHRUB', 'SHRUG', 'SHYLY', 'SIEGE', 'SISSY', 'SKILL', 'SKIMP', 'SKIRT', 'SKUNK', 'SLATE', 'SLEEK', 'SLOSH', 'SLOTH', 'SLUMP', 'SLUNG', 'SMART', 'SMASH', 'SMEAR', 'SMELT', 'SMILE', 'SMIRK', 'SMITE', 'SNACK', 'SNAFU', 'SNAIL', 'SNAKY', 'SNARE', 'SNARL', 'SNEAK', 'SNOUT', 'SOGGY', 'SOLAR', 'SOLVE', 'SONIC', 'SOUND', 'SOWER', 'SPACE', 'SPADE', 'SPELL', 'SPEND', 'SPICE', 'SPICY', 'SPIEL', 'SPIKE', 'SPILL', 'SPIRE', 'SPLAT', 'SPOKE', 'SPRAY', 'SPURT', 'SQUAD', 'SQUAT', 'STAFF', 'STAGE', 'STAID', 'STAIR', 'STALE', 'STAND', 'START', 'STEAD', 'STEED', 'STEIN', 'STICK', 'STING', 'STINK', 'STOCK', 'STOMP', 'STONE', 'STOOL', 'STORE', 'STORY', 'STOUT', 'STOVE', 'STRAP', 'STRAW', 'STUDY', 'STYLE', 'SUGAR', 'SULKY', 'SURER', 'SURLY', 'SWEAT', 'SWEEP', 'SWEET', 'SWILL', 'SWINE', 'SWIRL', 'SYRUP', 'TACIT', 'TANGY', 'TAPER', 'TAPIR', 'TASTE', 'TASTY', 'TAUNT', 'TEASE', 'TENTH', 'TEPID', 'THEIR', 'THEME', 'THERE', 'THIEF', 'THIRD', 'THORN', 'THOSE', 'THUMB', 'THUMP', 'THYME', 'TIARA', 'TIBIA', 'TIGER', 'TILDE', 'TIPSY', 'TODAY', 'TONIC', 'TOPAZ', 'TORSO', 'TOTEM', 'TOUGH', 'TOXIC', 'TRACE', 'TRACT', 'TRAIN', 'TRAIT', 'TRASH', 'TRAWL', 'TREAT', 'TREND', 'TRIAD', 'TRICE', 'TRITE', 'TROLL', 'TROPE', 'TROVE', 'TRUSS', 'TRUTH', 'TRYST', 'TWANG', 'TWEED', 'TWICE', 'TWINE', 'ULCER', 'ULTRA', 'UNCLE', 'UNDER', 'UNDUE', 'UNFED', 'UNFIT', 'UNIFY', 'UNITE', 'UNLIT', 'UNMET', 'UNTIE', 'UNZIP', 'UPSET', 'USAGE', 'USHER', 'USING', 'USUAL', 'USURP', 'UTTER', 'VAGUE', 'VALET', 'VALID', 'VENOM', 'VERVE', 'VIGOR', 'VIOLA', 'VIRAL', 'VITAL', 'VIVID', 'VODKA', 'VOICE', 'VOTER', 'VOUCH', 'WACKY', 'WALTZ', 'WASTE', 'WATCH', 'WEARY', 'WEDGE', 'WHACK', 'WHALE', 'WHEEL', 'WHELP', 'WHERE', 'WHIFF', 'WHILE', 'WHINE', 'WHIRL', 'WHISK', 'WHOOP', 'WINCE', 'WINDY', 'WOKEN', 'WOOER', 'WORDY', 'WORLD', 'WORRY', 'WORSE', 'WOVEN', 'WRATH', 'WRITE', 'WRONG', 'WROTE', 'WRUNG', 'YACHT', 'YEARN', 'YIELD', 'YOUTH', 'ZESTY']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.rockpapershotgun.com/wordle-past-answers\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "OldWords = []\n",
    "for li in soup.select(\"ul.inline li\"):\n",
    "  OldWords.append(li.text)\n",
    "\n",
    "print(OldWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of OldWords: 855\n",
      "Length of five_letter_words before update: 10230\n",
      "Length of five_letter_words after update: 9399\n"
     ]
    }
   ],
   "source": [
    "def remove_words(five_letter_words, OldWords):\n",
    "  \"\"\"Removes all words from `five_letter_words` that are also in `words`.\"\"\"\n",
    "\n",
    "  print(f\"Length of OldWords: {len(OldWords)}\")\n",
    "  print(f\"Length of five_letter_words before update: {len(five_letter_words)}\")\n",
    "\n",
    "  for word in OldWords:\n",
    "    if word in five_letter_words:\n",
    "      five_letter_words.remove(word)\n",
    "\n",
    "  print(f\"Length of five_letter_words after update: {len(five_letter_words)}\")\n",
    "\n",
    "\n",
    "remove_words(five_letter_words, OldWords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most common letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common Letters:\n",
      "A: 5425\n",
      "E: 4462\n",
      "R: 3221\n",
      "I: 3084\n",
      "O: 3024\n",
      "S: 2674\n",
      "N: 2594\n",
      "L: 2548\n",
      "T: 2453\n",
      "U: 2143\n",
      "Y: 1717\n",
      "C: 1657\n",
      "D: 1543\n",
      "M: 1523\n",
      "H: 1433\n",
      "P: 1353\n",
      "B: 1276\n",
      "G: 1174\n",
      "K: 1017\n",
      "W: 680\n",
      "F: 659\n",
      "V: 494\n",
      "Z: 291\n",
      "J: 240\n",
      "X: 223\n",
      "Q: 87\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to count letter frequency in 5-letter words\n",
    "def count_letter_frequency(words_list):\n",
    "    letter_frequency = Counter()\n",
    "    for word in words_list:\n",
    "        letter_frequency.update(word)\n",
    "    return letter_frequency\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    letter_frequency = count_letter_frequency(five_letter_words)\n",
    "    \n",
    "    # Sort the letter frequency by count (highest to lowest)\n",
    "    sorted_frequency = sorted(letter_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Print the top 10 most common letters\n",
    "    print(\"Top 10 Most Common Letters:\")\n",
    "    for letter, count in sorted_frequency[:100]:\n",
    "        print(f\"{letter}: {count}\")\n",
    "\n",
    "    # Extract the top 10 most common letters\n",
    "    top_common_letters = [letter for letter, _ in sorted_frequency[:100]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only word matching top 10 letters.\n",
    "Return the first non-empty list when exluding word matching the top 10 common letters in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "['DONGA', 'SCAUR', 'SCAWL', 'ICACO', 'LUCIA']\n",
      "E\n",
      "['RENAL', 'CRARE', 'BEGAR', 'DRAKE', 'ASKER']\n",
      "R\n",
      "['RENAL', 'CRARE', 'BEGAR', 'DRAKE', 'ASKER']\n",
      "I\n",
      "['ERICA', 'ACIER', 'VAIRE', 'DEAIR', 'AIDER']\n",
      "S\n",
      "['ARIES', 'RAISE', 'SERAI', 'ARISE']\n",
      "['ARIES', 'RAISE', 'SERAI', 'ARISE']\n"
     ]
    }
   ],
   "source": [
    "def filter_words_by_top_common_letters(words_list, top_common_letters):\n",
    "    filtered_words = words_list.copy()  # Make a copy of the original list\n",
    "    \n",
    "    for letter in top_common_letters:\n",
    "        # Keep only words containing the current letter\n",
    "        filtered_words_ = [word for word in filtered_words if letter in word]\n",
    "        \n",
    "        if len(filtered_words_) == 0:  # Check if filtered_words_ is empty\n",
    "            continue\n",
    "            ##return filtered_words\n",
    "        \n",
    "        filtered_words = filtered_words_\n",
    "        print(letter)\n",
    "        print(filtered_words[:5])\n",
    "    \n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "starting_words = filter_words_by_top_common_letters(five_letter_words, top_common_letters)\n",
    "print(starting_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'R', 'A', 'E', 'S']\n"
     ]
    }
   ],
   "source": [
    "def extract_unique_letters(starting_words):\n",
    "    unique_letters = set()\n",
    "    for word in starting_words:\n",
    "        for letter in word:\n",
    "            unique_letters.add(letter)\n",
    "    return list(unique_letters)\n",
    "\n",
    "\n",
    "starting_letters = extract_unique_letters(starting_words)\n",
    "print(starting_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 2, 'R': 3, 'A': 2, 'E': 4, 'S': 1}\n",
      "['ARIES', 'RAISE', 'SERAI', 'ARISE']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def find_most_common_positions(unique_letters, five_letter_words):\n",
    "    letter_positions = defaultdict(list)\n",
    "\n",
    "    # Initialize the defaultdict with lists for each letter\n",
    "    for letter in unique_letters:\n",
    "        letter_positions[letter] = []\n",
    "\n",
    "    # Iterate through each word in five_letter_words and record positions of letters\n",
    "    for word in five_letter_words:\n",
    "        for i, letter in enumerate(word):\n",
    "            if letter in unique_letters:\n",
    "                letter_positions[letter].append(i + 1)  # Add 1 to convert to 1-based indexing\n",
    "\n",
    "    # Find the most common position for each letter\n",
    "    most_common_positions = {}\n",
    "    for letter, positions in letter_positions.items():\n",
    "        if positions:\n",
    "            most_common_position = max(set(positions), key=positions.count)\n",
    "            most_common_positions[letter] = most_common_position\n",
    "\n",
    "    return most_common_positions\n",
    "\n",
    "# Usage\n",
    "common_positions = find_most_common_positions(starting_letters, five_letter_words)\n",
    "print(common_positions)\n",
    "print(starting_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Wordel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words_by_conditions(words_list, required_letters, position_conditions, do_not_use, do_not_use_positions):\n",
    "    filtered_words = []\n",
    "\n",
    "    for word in words_list:\n",
    "        # Check if the word contains letters that should not be in specific positions\n",
    "        if do_not_use_positions:\n",
    "            valid_word = True\n",
    "            for position, letter in do_not_use_positions.items():\n",
    "                position = int(position.lstrip(\"Pos\"))  # Convert position to an integer\n",
    "                if (\n",
    "                    len(word) >= position and\n",
    "                    word[position - 1] == letter\n",
    "                ):\n",
    "                    valid_word = False\n",
    "                    break\n",
    "            if not valid_word:\n",
    "                continue\n",
    "\n",
    "        # Check condition one: if required_letters is specified, ensure all letters are in the word\n",
    "        if required_letters and not all(letter in word for letter in required_letters):\n",
    "            continue\n",
    "        \n",
    "        # Check condition two: if position_conditions is specified, ensure letters are in the correct positions\n",
    "        if position_conditions:\n",
    "            valid_word = True\n",
    "            for position, letter in position_conditions.items():\n",
    "                position = int(position.lstrip(\"Pos\"))  # Convert position to an integer\n",
    "                if len(word) < position or word[position - 1] != letter:\n",
    "                    valid_word = False\n",
    "                    break\n",
    "            if not valid_word:\n",
    "                continue\n",
    "        \n",
    "        # Check if the word contains letters that should not be in the word\n",
    "        if do_not_use and any(letter in word for letter in do_not_use):\n",
    "            continue\n",
    "\n",
    "        # If the word meets all conditions, add it to the filtered list\n",
    "        filtered_words.append(word)\n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find a new best word.\n",
    "\n",
    "def find_top_common_letters(words_list):\n",
    "    # Calculate letter frequency in the list of words\n",
    "    letter_frequency = count_letter_frequency(words_list)\n",
    "    \n",
    "    # Sort the letter frequency by count (highest to lowest)\n",
    "    sorted_frequency = sorted(letter_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Print the top 10 most common letters\n",
    "    print(\"Top 10 Most Common Letters:\")\n",
    "    for letter, count in sorted_frequency[:100]:\n",
    "        print(f\"{letter}: {count}\")\n",
    "    \n",
    "    # Extract the top 10 most common letters\n",
    "    top_common_letters = [letter for letter, _ in sorted_frequency[:100]]\n",
    "    \n",
    "    return top_common_letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "required_letters = [\"A\", \"S\", \"L\"]\n",
    "position_conditions = {\"Pos2\": \"L\", \"Pos3\": \"A\"}\n",
    "do_not_use = [\"R\", \"I\", \"E\" ,\"N\", \"T\", \"P\", \"H\"]\n",
    "do_not_use_positions = {\"Pos1\": \"S\"}  # \"A\" should not be in position 3\n",
    "\n",
    "five_letter_words = filter_words_by_conditions(five_letter_words, required_letters, position_conditions, do_not_use, do_not_use_positions)\n",
    "print(five_letter_words)\n",
    "print(len(five_letter_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common Letters:\n",
      "S: 9\n",
      "L: 8\n",
      "A: 8\n",
      "H: 4\n",
      "P: 4\n",
      "C: 2\n",
      "B: 1\n",
      "F: 1\n",
      "K: 1\n",
      "U: 1\n",
      "S\n",
      "['BLASH', 'CLASP', 'CLASH', 'PLASH', 'PLASS']\n",
      "L\n",
      "['BLASH', 'CLASP', 'CLASH', 'PLASH', 'PLASS']\n",
      "A\n",
      "['BLASH', 'CLASP', 'CLASH', 'PLASH', 'PLASS']\n",
      "H\n",
      "['BLASH', 'CLASH', 'PLASH', 'FLASH']\n",
      "P\n",
      "['PLASH']\n",
      "['PLASH']\n"
     ]
    }
   ],
   "source": [
    "#Update letter frequency\n",
    "letter_frequency = count_letter_frequency(five_letter_words)\n",
    "\n",
    "# Sort the letter frequency by count (highest to lowest)\n",
    "sorted_frequency = sorted(letter_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "  \n",
    "# Print the top 10 most common letters\n",
    "print(\"Top 10 Most Common Letters:\")\n",
    "for letter, count in sorted_frequency[:100]:\n",
    "    print(f\"{letter}: {count}\")\n",
    "\n",
    "# Extract the top 10 most common letters\n",
    "top_common_letters = [letter for letter, _ in sorted_frequency[:100]]\n",
    "\n",
    "# Get the word with the most common letters left\n",
    "five_letter_words = filter_words_by_top_common_letters(five_letter_words, top_common_letters)\n",
    "print(five_letter_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
